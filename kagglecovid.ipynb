{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/input/covid19-global-forecasting-week-3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 23563\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import csv\n",
    "filename = \"train.csv\"\n",
    "  \n",
    "# initializing the titles and rows list \n",
    "fields = [] \n",
    "rows = [] \n",
    "  \n",
    "# reading csv file \n",
    "with open('../input/covid19-global-forecasting-week-3/train.csv', 'r') as csvfile: \n",
    "    # creating a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extracting field names through first row \n",
    "    fields = next(csvreader) \n",
    "  \n",
    "    # extracting each data row one by one \n",
    "    for row in csvreader: \n",
    "        rows.append(row) \n",
    "  \n",
    "    # get total number of rows \n",
    "    print(\"Total no. of rows: %d\"%(csvreader.line_num)) \n",
    "countries=[]\n",
    "datecol=[]\n",
    "dates=[]\n",
    "res=[]\n",
    "for row in rows:\n",
    "    row[2]=row[1]+' '+row[2]\n",
    "    del row[1]\n",
    "    #del row[1]\n",
    "    del row[4]\n",
    "    countries.append(row[1])\n",
    "    dates.append(row[2])   \n",
    "[res.append(x) for x in countries if x not in res] \n",
    "countries=res\n",
    "res=[]\n",
    "[res.append(x) for x in dates if x not in res] \n",
    "dates=res\n",
    "with open('/kaggle/working/cases_split.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    countries[:0] = ['Date']\n",
    "    csvwriter.writerow(countries)\n",
    "    for date in dates:\n",
    "        date=[date]\n",
    "        datecol.append(date)\n",
    "\n",
    "    for date in dates :\n",
    "        for row in rows:\n",
    "        \n",
    "            temprow=[]\n",
    "            if row[2]==date:\n",
    "                for datecolrow in datecol:\n",
    "                    if datecolrow[0]==date:\n",
    "                        if type(datecolrow)==str:\n",
    "                            temprow=[datecolrow]\n",
    "                        else:\n",
    "                            temprow=datecolrow\n",
    "                        temprow.append(row[3]) \n",
    "\n",
    "                        datecolrow=temprow  \n",
    "                    \n",
    "    csvwriter.writerows(datecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  cases_split.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 23563\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "filename = \"../input/covid19-global-forecasting-week-3/train.csv\"\n",
    "  \n",
    "# initializing the titles and rows list \n",
    "fields = [] \n",
    "rows = [] \n",
    "  \n",
    "# reading csv file \n",
    "with open(filename, 'r') as csvfile: \n",
    "    # creating a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extracting field names through first row \n",
    "    fields = next(csvreader) \n",
    "  \n",
    "    # extracting each data row one by one \n",
    "    for row in csvreader: \n",
    "        rows.append(row) \n",
    "  \n",
    "    # get total number of rows \n",
    "    print(\"Total no. of rows: %d\"%(csvreader.line_num)) \n",
    "countries=[]\n",
    "datecol=[]\n",
    "dates=[]\n",
    "res=[]\n",
    "for row in rows:\n",
    "    row[2]=row[1]+' '+row[2]\n",
    "    del row[1]\n",
    "    #del row[1]\n",
    "    del row[3]\n",
    "    countries.append(row[1])\n",
    "    dates.append(row[2])   \n",
    "[res.append(x) for x in countries if x not in res] \n",
    "countries=res\n",
    "res=[]\n",
    "[res.append(x) for x in dates if x not in res] \n",
    "dates=res\n",
    "with open('/kaggle/working/deaths_split.csv', 'w', newline='') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    countries[:0] = ['Date']\n",
    "    csvwriter.writerow(countries)\n",
    "    for date in dates:\n",
    "        date=[date]\n",
    "        datecol.append(date)\n",
    "\n",
    "    for date in dates :\n",
    "        for row in rows:\n",
    "        \n",
    "            temprow=[]\n",
    "            if row[2]==date:\n",
    "                for datecolrow in datecol:\n",
    "                    if datecolrow[0]==date:\n",
    "                        if type(datecolrow)==str:\n",
    "                            temprow=[datecolrow]\n",
    "                        else:\n",
    "                            temprow=datecolrow\n",
    "                        temprow.append(row[3]) \n",
    "\n",
    "                        datecolrow=temprow  \n",
    "                    \n",
    "    csvwriter.writerows(datecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression\n",
    "%matplotlib inline\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('/kaggle/working/cases_split.csv')\n",
    "#X = dataset.iloc[:, 0:1].values\n",
    "X=[]\n",
    "result=[]\n",
    "\n",
    "def listtostr(s):  \n",
    "    res = float(str(s)[1:-1])\n",
    "    return (res)\n",
    "\n",
    "for i in range(1,len(dataset.columns)):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    y = dataset.iloc[:, i].values\n",
    "    for n in range(1,len(y)+1):\n",
    "        X.append([n])\n",
    "    #print(y)\n",
    "    #print(X)\n",
    "    #X = X[40:]\n",
    "    #y = y[40:]\n",
    "    # Fitting Polynomial Regression to the dataset\n",
    "    \n",
    "    poly_reg = PolynomialFeatures(degree = 4)\n",
    "    X_poly = poly_reg.fit_transform(X)\n",
    "    poly_reg.fit(X_poly, y)\n",
    "    lin_reg_2 = LinearRegression()\n",
    "    lin_reg_2.fit(X_poly, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Visualising the Polynomial Regression results\n",
    "#     plt.scatter(X, y, color = 'red')\n",
    "#     predline=[]\n",
    "#     for n in range(1,108):\n",
    "#         predline.append([n])\n",
    "#     #predline = predline[40:]    \n",
    "#     plt.plot(predline, lin_reg_2.predict(poly_reg.fit_transform(predline)), color = 'blue')\n",
    "    \n",
    "#     plt.title(dataset.columns[i])\n",
    "#     plt.xlabel('Days')\n",
    "#     plt.ylabel('Cases')\n",
    "#     plt.show()\n",
    "    for n in range(65,108):\n",
    "        result.append(listtostr(lin_reg_2.predict(poly_reg.fit_transform([[n]]))))\n",
    "    \n",
    "ids=[]        \n",
    "for i in range(1,len(result)+1):\n",
    "    ids.append(i)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df[\"ForecastId\"] = pd.Series(ids)\n",
    "df[\"ConfirmedCases\"] = pd.Series(result)\n",
    "# Polynomial Regression\n",
    "%matplotlib inline\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('/kaggle/working/deaths_split.csv')\n",
    "#X = dataset.iloc[:, 0:1].values\n",
    "X=[]\n",
    "result=[]\n",
    "\n",
    "def listtostr(s):  \n",
    "    res = float(str(s)[1:-1])\n",
    "    return (res)\n",
    "\n",
    "for i in range(1,len(dataset.columns)):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    y = dataset.iloc[:, i].values\n",
    "    for n in range(1,len(y)+1):\n",
    "        X.append([n])\n",
    "    #print(y)\n",
    "    #print(X)\n",
    "    #X = X[40:]\n",
    "    #y = y[40:]\n",
    "    # Fitting Polynomial Regression to the dataset\n",
    "    \n",
    "    poly_reg = PolynomialFeatures(degree = 4)\n",
    "    X_poly = poly_reg.fit_transform(X)\n",
    "    poly_reg.fit(X_poly, y)\n",
    "    lin_reg_2 = LinearRegression()\n",
    "    lin_reg_2.fit(X_poly, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Visualising the Polynomial Regression results\n",
    "#     plt.scatter(X, y, color = 'red')\n",
    "#     predline=[]\n",
    "#     for n in range(1,108):\n",
    "#         predline.append([n])\n",
    "#     #predline = predline[40:]    \n",
    "#     plt.plot(predline, lin_reg_2.predict(poly_reg.fit_transform(predline)), color = 'blue')\n",
    "    \n",
    "#     plt.title(dataset.columns[i])\n",
    "#     plt.xlabel('Days')\n",
    "#     plt.ylabel('Cases')\n",
    "#     plt.show()\n",
    "    for n in range(65,108):\n",
    "        result.append(listtostr(lin_reg_2.predict(poly_reg.fit_transform([[n]]))))\n",
    "        \n",
    "df[\"Fatalities\"] = pd.Series(result)\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
